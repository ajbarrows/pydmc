{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RDEX-ABCD Model Tutorial\n\nThis notebook demonstrates the **RDEX-ABCD model** for analyzing stop-signal task data from the ABCD study.\n\n**Reference**: Weigard, A., Matzke, D., Tanis, C., & Heathcote, A. (2023). A cognitive process modeling framework for the ABCD study stop-signal task. *Developmental Cognitive Neuroscience, 59*, 101191.\n\n## Overview\n\n1. Generate synthetic ABCD stop-signal data with context independence violations\n2. Fit the RDEX-ABCD model\n3. Verify parameter recovery\n4. Demonstrate that the model captures key patterns from Weigard et al. (2023):\n   - Choice accuracy increases with SSD on stop trials\n   - SSD-dependent drift rates account for stimulus replacement\n   - Separation of processing speed, perceptual growth, and inhibition"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport arviz as az\n\n# Import the RDEX-ABCD model\nimport sys\nsys.path.insert(0, '..')  # Add parent directory to path\nfrom pydmc import RDEXABCDModel\n\n# Plotting settings\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\n%matplotlib inline\n\n# Random seed for reproducibility\nnp.random.seed(42)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. The ABCD Task and Context Independence Violation\n\n### Standard Stop-Signal Task\nIn standard stop-signal tasks, the go stimulus remains visible when the stop signal appears, maintaining \"context independence\" - the go process is identical on go and stop trials.\n\n### ABCD Task Design\nThe ABCD study's stop-signal task has a critical difference: **the stop signal replaces the go stimulus**. This means:\n- At short SSDs, participants have limited time to process the choice stimulus\n- At SSD = 0, no choice information is available (chance accuracy expected)\n- As SSD increases, more processing time is available before the stimulus disappears\n\n### RDEX-ABCD Solution (Weigard et al., 2023)\nThe model accounts for this by implementing **SSD-dependent drift rates**:\n- **v0**: Processing speed (base rate without discrimination)\n- **g**: Perceptual growth rate (how discrimination improves with SSD)\n- **v+, v-**: Asymptotic drift rates (reached at long SSDs)\n\nThe drift rates grow as: `v(SSD) = v0 + min(g * SSD, v_asymptote - v0)`"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Generate Synthetic Data\n\nGenerate synthetic ABCD stop-signal data with context independence violations to test parameter recovery."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def simulate_abcd_stop_signal_data(n_subjects=10, n_go_per_subject=300, n_stop_per_subject=60, seed=42):\n    \"\"\"\n    Simulate ABCD stop-signal data with context independence violations.\n    \n    Implements the RDEX-ABCD data-generating process with SSD-dependent drift rates.\n    \"\"\"\n    np.random.seed(seed)\n    \n    all_data = []\n    true_params = []\n    \n    MAX_RT = 1.5\n    \n    for subj_idx in range(n_subjects):\n        # Individual-level parameters\n        params = {\n            'subject_id': f'sub-{subj_idx:03d}',\n            'B': np.random.lognormal(-0.2, 0.15) + 0.5,\n            't0': np.random.beta(3, 17) + 0.08,\n            'v_plus': np.random.normal(3.5, 0.3),\n            'v_minus': np.random.normal(1.0, 0.3),\n            'v0': np.random.normal(2.2, 0.25),\n            'g': np.random.gamma(4, 0.6),\n            'ssrt_mu': np.random.normal(0.20, 0.03),\n            'ssrt_sigma': np.random.gamma(2, 0.02),\n            'ssrt_tau': np.random.gamma(3, 0.015),\n            'ptf': np.random.beta(2, 20),\n            'pgf': np.random.beta(2, 30),\n        }\n        true_params.append(params)\n        \n        # Simulate GO trials\n        for trial_idx in range(n_go_per_subject):\n            stimulus = np.random.randint(0, 2)\n            \n            if np.random.rand() < params['pgf']:\n                all_data.append({\n                    'subject': params['subject_id'],\n                    'trial_type': 'go',\n                    'stimulus': stimulus,\n                    'response': 0,\n                    'rt': np.nan,\n                    'ssd': np.nan\n                })\n                continue\n            \n            max_attempts = 100\n            for attempt in range(max_attempts):\n                t_match = stats.invgauss.rvs(\n                    mu=params['B'] / params['v_plus'],\n                    scale=params['B']**2\n                )\n                t_mismatch = stats.invgauss.rvs(\n                    mu=params['B'] / max(params['v_minus'], 0.3),\n                    scale=params['B']**2\n                )\n                \n                if t_match < t_mismatch:\n                    response = stimulus + 1\n                    rt = params['t0'] + t_match\n                else:\n                    response = 2 - stimulus\n                    rt = params['t0'] + t_mismatch\n                \n                if rt <= MAX_RT:\n                    break\n            else:\n                rt = params['t0'] + np.random.uniform(0.2, 0.5)\n                response = stimulus + 1\n            \n            all_data.append({\n                'subject': params['subject_id'],\n                'trial_type': 'go',\n                'stimulus': stimulus,\n                'response': response,\n                'rt': rt,\n                'ssd': np.nan\n            })\n        \n        # Simulate STOP trials\n        for _ in range(n_stop_per_subject):\n            stimulus = np.random.randint(0, 2)\n            ssd = np.random.uniform(0.05, 0.45)\n            trigger_failed = np.random.rand() < params['ptf']\n            \n            # SSD-dependent drift rates\n            discrimination_growth = min(params['g'] * ssd, params['v_plus'] - params['v0'])\n            v_plus_ssd = params['v0'] + discrimination_growth\n            \n            v_minus_discrimination = min(params['g'] * ssd, abs(params['v_minus'] - params['v0']))\n            if params['v_minus'] < params['v0']:\n                v_minus_ssd = params['v0'] - v_minus_discrimination\n            else:\n                v_minus_ssd = params['v0'] + v_minus_discrimination\n            \n            if np.random.rand() < params['pgf']:\n                all_data.append({\n                    'subject': params['subject_id'],\n                    'trial_type': 'successful_stop',\n                    'stimulus': stimulus,\n                    'response': 0,\n                    'rt': np.nan,\n                    'ssd': ssd\n                })\n                continue\n            \n            max_attempts = 50\n            for attempt in range(max_attempts):\n                t_match = stats.invgauss.rvs(\n                    mu=params['B'] / max(v_plus_ssd, 0.3),\n                    scale=params['B']**2\n                )\n                t_mismatch = stats.invgauss.rvs(\n                    mu=params['B'] / max(v_minus_ssd, 0.3),\n                    scale=params['B']**2\n                )\n                \n                if t_match < t_mismatch:\n                    go_response = stimulus + 1\n                    go_rt = params['t0'] + t_match\n                else:\n                    go_response = 2 - stimulus\n                    go_rt = params['t0'] + t_mismatch\n                \n                if go_rt <= MAX_RT:\n                    break\n            else:\n                go_rt = params['t0'] + np.random.uniform(0.2, 0.5)\n                go_response = stimulus + 1\n            \n            if not trigger_failed:\n                normal_part = np.random.normal(params['ssrt_mu'], params['ssrt_sigma'])\n                exp_part = np.random.exponential(params['ssrt_tau'])\n                ssrt_sample = max(normal_part + exp_part, 0.05)\n                stop_rt = ssd + ssrt_sample\n            else:\n                stop_rt = np.inf\n            \n            if go_rt < stop_rt:\n                all_data.append({\n                    'subject': params['subject_id'],\n                    'trial_type': 'signal_respond',\n                    'stimulus': stimulus,\n                    'response': go_response,\n                    'rt': go_rt,\n                    'ssd': ssd\n                })\n            else:\n                all_data.append({\n                    'subject': params['subject_id'],\n                    'trial_type': 'successful_stop',\n                    'stimulus': stimulus,\n                    'response': 0,\n                    'rt': np.nan,\n                    'ssd': ssd\n                })\n    \n    df = pd.DataFrame(all_data)\n    params_df = pd.DataFrame(true_params)\n    \n    return df, params_df\n\n# Generate data\ndata, true_params = simulate_abcd_stop_signal_data(\n    n_subjects=10,\n    n_go_per_subject=300,\n    n_stop_per_subject=60,\n    seed=42\n)\n\nprint(f\"Generated {len(data)} trials from {data['subject'].nunique()} subjects\")\nprint(f\"  Go trials: {(data['trial_type'] == 'go').sum()}\")\nprint(f\"  Signal-respond trials: {(data['trial_type'] == 'signal_respond').sum()}\")\nprint(f\"  Successful stops: {(data['trial_type'] == 'successful_stop').sum()}\")\n\ndata.head(10)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Verify Context Independence Violation\n\nConfirm that the synthetic data exhibits the key pattern from Weigard et al. (2023): choice accuracy on signal-respond trials increases with SSD."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute choice accuracy for signal-respond trials by SSD\nsignal_respond = data[data['trial_type'] == 'signal_respond'].copy()\n\nsignal_respond['correct'] = (\n    ((signal_respond['stimulus'] == 0) & (signal_respond['response'] == 1)) |\n    ((signal_respond['stimulus'] == 1) & (signal_respond['response'] == 2))\n).astype(int)\n\nsignal_respond['ssd_bin'] = pd.cut(signal_respond['ssd'], bins=5)\n\naccuracy_by_ssd = signal_respond.groupby('ssd_bin')['correct'].agg(['mean', 'sem', 'count']).reset_index()\naccuracy_by_ssd['ssd_midpoint'] = accuracy_by_ssd['ssd_bin'].apply(lambda x: x.mid)\n\n# Plot\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Left: Choice accuracy by SSD\nax = axes[0]\nax.errorbar(accuracy_by_ssd['ssd_midpoint'], accuracy_by_ssd['mean'],\n            yerr=accuracy_by_ssd['sem'], marker='o', markersize=8,\n            capsize=5, capthick=2, linewidth=2)\nax.axhline(0.5, color='gray', linestyle='--', label='Chance')\nax.set_xlabel('Stop-Signal Delay (s)', fontsize=12)\nax.set_ylabel('Choice Accuracy', fontsize=12)\nax.set_title('Context Independence Violation\\n(Accuracy increases with SSD)', fontsize=13, fontweight='bold')\nax.set_ylim([0.4, 1.0])\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Right: Inhibition function\nax = axes[1]\nstop_trials = data[data['trial_type'].isin(['signal_respond', 'successful_stop'])].copy()\nstop_trials['responded'] = (stop_trials['response'] > 0).astype(int)\nstop_trials['ssd_bin'] = pd.cut(stop_trials['ssd'], bins=5)\n\ninhib_func = stop_trials.groupby('ssd_bin')['responded'].agg(['mean', 'sem']).reset_index()\ninhib_func['ssd_midpoint'] = inhib_func['ssd_bin'].apply(lambda x: x.mid)\n\nax.errorbar(inhib_func['ssd_midpoint'], inhib_func['mean'],\n            yerr=inhib_func['sem'], marker='s', markersize=8,\n            capsize=5, capthick=2, linewidth=2, color='coral')\nax.set_xlabel('Stop-Signal Delay (s)', fontsize=12)\nax.set_ylabel('P(Respond | Stop Signal)', fontsize=12)\nax.set_title('Inhibition Function', fontsize=13, fontweight='bold')\nax.set_ylim([0, 1.0])\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Accuracy range: {accuracy_by_ssd['mean'].iloc[0]:.2f} (short SSD) to {accuracy_by_ssd['mean'].iloc[-1]:.2f} (long SSD)\")\nprint(f\"P(respond) range: {inhib_func['mean'].iloc[0]:.2f} to {inhib_func['mean'].iloc[-1]:.2f}\")\nprint(\"\\nLeft panel demonstrates the context independence violation that RDEX-ABCD models.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Fit the RDEX-ABCD Model\n\nFit the hierarchical RDEX-ABCD model to the synthetic data. Note: Using reduced samples for speed. For publication analyses, use draws=1000+, tune=1000+, chains=4."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create and fit model\nmodel = RDEXABCDModel(use_hierarchical=True)\n\ntrace = model.fit(\n    data,\n    draws=100,        # Use 1000+ for real analysis\n    tune=100,         # Use 1000+ for real analysis  \n    chains=2,         # Use 4 for real analysis\n    target_accept=0.9,\n    return_inferencedata=True\n)\n\nprint(\"Model fitting complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Convergence Diagnostics"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary statistics\nsummary = az.summary(\n    trace,\n    var_names=['mu_B', 'mu_t0', 'mu_v_plus', 'mu_v_minus', 'mu_v0', 'mu_g',\n               'mu_stop_mu', 'mu_pgf_probit', 'mu_ptf_probit']\n)\n\nprint(\"GROUP-LEVEL PARAMETER SUMMARY\")\nprint(\"=\"*70)\nprint(summary)\nprint(\"\\nFor convergence: Rhat < 1.01, ESS > 400\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Trace plots for key parameters\nvar_names = ['mu_v_plus', 'mu_v_minus', 'mu_v0', 'mu_g']\naz.plot_trace(\n    trace,\n    var_names=var_names,\n    compact=True,\n    figsize=(12, 8)\n)\nplt.suptitle('MCMC Traces: Context Independence Parameters', fontsize=14, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Parameter Recovery\n\nEvaluate whether the model recovers the true parameters used to generate the data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract posterior means\nposterior = trace.posterior\n\nestimates = {\n    'B': posterior['mu_B'].mean().item(),\n    't0': posterior['mu_t0'].mean().item(),\n    'v_plus': posterior['mu_v_plus'].mean().item(),\n    'v_minus': posterior['mu_v_minus'].mean().item(),\n    'v0': posterior['mu_v0'].mean().item(),\n    'g': posterior['mu_g'].mean().item(),\n}\n\ntrue_values = {\n    'B': true_params['B'].mean(),\n    't0': true_params['t0'].mean(),\n    'v_plus': true_params['v_plus'].mean(),\n    'v_minus': true_params['v_minus'].mean(),\n    'v0': true_params['v0'].mean(),\n    'g': true_params['g'].mean(),\n}\n\n# Create recovery plot\nfig, ax = plt.subplots(figsize=(8, 8))\n\nparams = list(estimates.keys())\nest_vals = [estimates[p] for p in params]\ntrue_vals = [true_values[p] for p in params]\n\nax.scatter(true_vals, est_vals, s=100, alpha=0.7)\nfor i, param in enumerate(params):\n    ax.annotate(param, (true_vals[i], est_vals[i]), \n                xytext=(5, 5), textcoords='offset points', fontsize=11)\n\nlims = [min(true_vals + est_vals) * 0.9, max(true_vals + est_vals) * 1.1]\nax.plot(lims, lims, 'k--', alpha=0.5, linewidth=2, label='Perfect recovery')\n\nr = np.corrcoef(true_vals, est_vals)[0, 1]\n\nax.set_xlabel('True Parameter Value', fontsize=12)\nax.set_ylabel('Estimated Parameter Value', fontsize=12)\nax.set_title(f'Parameter Recovery (r = {r:.3f})', fontsize=13, fontweight='bold')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Print comparison table\nprint(\"PARAMETER RECOVERY\")\nprint(\"=\"*70)\nprint(f\"{'Parameter':<15} {'True Value':<15} {'Estimated':<15} {'Error %':<15}\")\nprint(\"-\"*70)\nfor param in params:\n    true = true_values[param]\n    est = estimates[param]\n    error = abs(est - true) / true * 100\n    print(f\"{param:<15} {true:<15.3f} {est:<15.3f} {error:<15.1f}\")\nprint(\"=\"*70)\nprint(f\"\\nCorrelation: {r:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Parameter Interpretation\n\nExtract and interpret the main parameters according to Weigard et al. (2023)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convert probit-scale failure probabilities\npgf_samples = stats.norm.cdf(posterior['mu_pgf_probit'].values.flatten())\nptf_samples = stats.norm.cdf(posterior['mu_ptf_probit'].values.flatten())\n\nssrt_samples = (posterior['mu_stop_mu'] + posterior.get('mu_stop_tau', 0)).values.flatten()\n\nprint(\"KEY PARAMETER ESTIMATES (Group Level)\")\nprint(\"=\"*70)\n\nprint(\"\\nGO PROCESS:\")\nprint(f\"  Threshold (B):                 {estimates['B']:.3f}\")\nprint(f\"  Non-decision time (t0):        {estimates['t0']:.3f} s\")\nprint(f\"  Matching drift rate (v+):      {estimates['v_plus']:.3f}\")\nprint(f\"  Mismatching drift rate (v-):   {estimates['v_minus']:.3f}\")\n\nprint(\"\\nCONTEXT INDEPENDENCE PARAMETERS (Weigard et al., 2023):\")\nprint(f\"  Processing speed (v0):         {estimates['v0']:.3f}\")\nprint(f\"  Perceptual growth rate (g):    {estimates['g']:.3f}\")\n\nprint(\"\\nSTOP PROCESS:\")\nprint(f\"  Stop-Signal RT (SSRT):         {np.mean(ssrt_samples):.3f} s\")\n\nprint(\"\\nFAILURE PROCESSES:\")\nprint(f\"  Go failure (pgf):              {np.mean(pgf_samples):.3f} ({np.mean(pgf_samples)*100:.1f}%)\")\nprint(f\"  Trigger failure (ptf):         {np.mean(ptf_samples):.3f} ({np.mean(ptf_samples)*100:.1f}%)\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Posterior Distributions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot posteriors for key parameters\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\naxes = axes.flatten()\n\nplot_params = [\n    ('mu_v_plus', 'v_plus', 'Matching Rate (v+)'),\n    ('mu_v_minus', 'v_minus', 'Mismatching Rate (v-)'),\n    ('mu_v0', 'v0', 'Processing Speed (v0)'),\n    ('mu_g', 'g', 'Perceptual Growth (g)'),\n    ('mu_stop_mu', 'ssrt_mu', 'Stop Process Î¼'),\n    ('mu_B', 'B', 'Threshold (B)'),\n]\n\nfor idx, (post_name, true_name, title) in enumerate(plot_params):\n    ax = axes[idx]\n    \n    samples = posterior[post_name].values.flatten()\n    ax.hist(samples, bins=30, density=True, alpha=0.7, edgecolor='black')\n    \n    true_val = true_params[true_name].mean()\n    ax.axvline(true_val, color='red', linewidth=3, linestyle='--', label=f'True: {true_val:.2f}')\n    \n    post_mean = samples.mean()\n    ax.axvline(post_mean, color='blue', linewidth=2, linestyle='-', label=f'Est: {post_mean:.2f}')\n    \n    ax.set_title(title, fontsize=11, fontweight='bold')\n    ax.set_xlabel('Value')\n    ax.set_ylabel('Density')\n    ax.legend(fontsize=9)\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. SSD-Dependent Drift Rates (Weigard et al., 2023)\n\nDemonstrate the key innovation of the RDEX-ABCD model: drift rates that grow linearly with SSD."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get posterior mean parameters\nv_plus_est = estimates['v_plus']\nv_minus_est = estimates['v_minus']\nv0_est = estimates['v0']\ng_est = estimates['g']\n\nssd_range = np.linspace(0, 0.5, 100)\n\ndef compute_rates(ssd, v_plus, v_minus, v0, g):\n    match_disc = np.minimum(g * ssd, v_plus - v0)\n    v_match = v0 + match_disc\n    \n    mismatch_disc = np.minimum(g * ssd, np.abs(v_minus - v0))\n    if v_minus < v0:\n        v_mismatch = v0 - mismatch_disc\n    else:\n        v_mismatch = v0 + mismatch_disc\n    \n    return v_match, v_mismatch\n\nv_match_curve, v_mismatch_curve = compute_rates(ssd_range, v_plus_est, v_minus_est, v0_est, g_est)\n\n# Plot\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# Left: Drift rates by SSD\nax = axes[0]\nax.plot(ssd_range, v_match_curve, linewidth=3, label='Matching accumulator (v+)', color='blue')\nax.plot(ssd_range, v_mismatch_curve, linewidth=3, label='Mismatching accumulator (v-)', color='red')\nax.axhline(v0_est, linestyle='--', color='gray', linewidth=2, label=f'Processing speed (v0 = {v0_est:.2f})')\nax.axhline(v_plus_est, linestyle=':', color='blue', linewidth=2, alpha=0.5, label=f'Asymptote v+ = {v_plus_est:.2f}')\nax.axhline(v_minus_est, linestyle=':', color='red', linewidth=2, alpha=0.5, label=f'Asymptote v- = {v_minus_est:.2f}')\nax.set_xlabel('Stop-Signal Delay (s)', fontsize=12)\nax.set_ylabel('Drift Rate', fontsize=12)\nax.set_title(f'SSD-Dependent Drift Rates (g = {g_est:.2f})', fontsize=13, fontweight='bold')\nax.legend(fontsize=9)\nax.grid(True, alpha=0.3)\n\n# Middle: Processing speed component\nax = axes[1]\nax.axhline(v0_est, linewidth=3, color='purple', label='Processing speed (v0)')\nax.fill_between([0, 0.5], [v0_est, v0_est], alpha=0.3, color='purple')\nax.set_xlabel('Stop-Signal Delay (s)', fontsize=12)\nax.set_ylabel('Rate', fontsize=12)\nax.set_title('Processing Speed Component', fontsize=13, fontweight='bold')\nax.set_ylim([0, max(v_plus_est, v0_est) * 1.2])\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Right: Discrimination component\nax = axes[2]\ndiscrimination_match = np.minimum(g_est * ssd_range, v_plus_est - v0_est)\ndiscrimination_mismatch = np.minimum(g_est * ssd_range, np.abs(v_minus_est - v0_est))\nax.plot(ssd_range, discrimination_match, linewidth=3, color='blue', label='Match discrimination')\nax.plot(ssd_range, discrimination_mismatch, linewidth=3, color='red', label='Mismatch discrimination')\nax.set_xlabel('Stop-Signal Delay (s)', fontsize=12)\nax.set_ylabel('Discrimination', fontsize=12)\nax.set_title('Discrimination Component', fontsize=13, fontweight='bold')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"SSD-DEPENDENT DRIFT RATE MODEL (Weigard et al., 2023)\")\nprint(\"=\"*70)\nprint(f\"At SSD=0: Both rates = v0 = {v0_est:.2f} (no discrimination)\")\nprint(f\"As SSD increases: Discrimination grows at rate g = {g_est:.2f}\")\nprint(f\"At long SSD: Rates asymptote to v+ = {v_plus_est:.2f}, v- = {v_minus_est:.2f}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Comparison to Standard Models\n\nExplanation of why RDEX-ABCD is necessary for ABCD data (Weigard et al., 2023)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"WHY THE RDEX-ABCD MODEL IS NECESSARY (Weigard et al., 2023)\")\nprint(\"=\"*70)\n\nprint(\"\\nStandard stop-signal models:\")\nprint(\"  - Assume constant drift rates across SSDs\")\nprint(\"  - Cannot explain increasing choice accuracy with SSD\")\nprint(\"  - Produce biased SSRT estimates\")\nprint(\"  - Confound processing speed with inhibition\")\n\nprint(\"\\nRDEX-ABCD model:\")\nprint(\"  - Models drift rate growth with SSD via v0 and g parameters\")\nprint(\"  - Accurately captures choice accuracy pattern\")\nprint(\"  - Provides unbiased SSRT estimates\")\nprint(\"  - Separates processing speed, perceptual efficiency, and inhibition\")\nprint(\"  - Distinguishes attention lapses (ptf) from inhibition deficits\")\n\nprint(\"\\nKey findings from this analysis:\")\nprint(f\"  - Processing speed (v0={v0_est:.2f}) enables some correct responses at SSD=0\")\nprint(f\"  - Perceptual growth (g={g_est:.2f}) determines discrimination improvement rate\")\nprint(f\"  - SSRT ({np.mean(ssrt_samples):.3f}s) reflects inhibition after accounting for v0, g, ptf\")\nprint(f\"  - Trigger failures ({np.mean(ptf_samples)*100:.1f}%) represent attention lapses\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis tutorial demonstrated:\n\n1. **Package functionality**: The `pydmc` implementation of RDEX-ABCD successfully fits hierarchical models to stop-signal data\n2. **Parameter recovery**: The model accurately recovers known parameters from synthetic data\n3. **Alignment with Weigard et al. (2023)**:\n   - Captures context independence violations (choice accuracy increases with SSD)\n   - Implements SSD-dependent drift rates via v0 and g parameters\n   - Separates processing speed, perceptual growth, and inhibition\n   - Accounts for trigger failures (attention lapses)\n\n### For real ABCD data analyses:\n\n```python\nfrom pydmc import RDEXABCDModel\nimport pandas as pd\n\n# Load data with columns: subject, stimulus, response, rt, ssd\ndata = pd.read_csv('abcd_stop_signal.csv')\n\n# Fit hierarchical model\nmodel = RDEXABCDModel(use_hierarchical=True)\ntrace = model.fit(data, draws=1000, tune=1000, chains=4)\n\n# Check convergence\nsummary = model.summary()\n\n# Extract parameters\nssrt = trace.posterior['ssrt']\nptf = trace.posterior['ptf']\nv0 = trace.posterior['v0']\ng = trace.posterior['g']\n```\n\n### Reference\n\nWeigard, A., Matzke, D., Tanis, C., & Heathcote, A. (2023). A cognitive process modeling framework for the ABCD study stop-signal task. *Developmental Cognitive Neuroscience, 59*, 101191."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}